{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library yang digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import operator as optr\n",
    "from collections import Counter\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metode yang digunakan untuk preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunct(sentence):\n",
    "    sentence=sentence.lower()                                   #Case Folding, mengubah semua huruf menjadi huruf kecil\n",
    "    #sentence=sentence.replace('<s>', '').replace('</s>', '')\n",
    "    sentence=re.sub(r\"\\d+\",\"\", sentence)                        #Filtering, menghapus angka\n",
    "    for punct in string.punctuation:\n",
    "        sentence=sentence.replace(punct,\"\")                     #Filtering, menghapus tanda baca\n",
    "    return \" \".join(sentence.split())                           #Tokenizing, mengubah teks menjadi token + mengubah list menjadi string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menentukan misspelled word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "Word Index\tWrong word\tCorrect word\tPrevious word\tNext word\n",
      "0 \t\t penelitina \t\t penelitian \t\t berdasarkan \t\t yang\n",
      "1 \t\t ksalahan \t\t kesalahan \t\t bahwa \t\t ejaan\n",
      "2 \t\t penggunan \t\t penggunaan \t\t kesalahan \t\t huruf\n",
      "3 \t\t yng \t\t yang \t\t baca \t\t meliputi\n",
      "4 \t\t krangnya \t\t kurangnya \t\t karena \t\t pemahaman\n",
      "\n",
      "Total misspelled word count 5\n"
     ]
    }
   ],
   "source": [
    "#Membaca file kamus\n",
    "with open('./INDONESIA.txt', 'r', encoding='utf8', errors='ignore') as f:\n",
    "    wordsFile = f.readlines() # list of valid urdu words, dictionary\n",
    "wordsList=list()\n",
    "for word in wordsFile:\n",
    "    word=word.lower().replace(\"-\",\"\")\n",
    "    wordsList.append(word[:-1])\n",
    "#membaca file uji\n",
    "def readFile(file):\n",
    "    word=[]\n",
    "    inputFile=open(file,'r', encoding=\"utf8\")\n",
    "    for line in inputFile:\n",
    "        line=removePunct(line)\n",
    "        line=line.strip().split()\n",
    "        for words in line:\n",
    "            word.append(words.strip())\n",
    "    inputFile.close()\n",
    "    return word\n",
    "\n",
    "errLineWords = readFile('Dokumen 1_Uji.txt')\n",
    "print(len(errLineWords))\n",
    "correctLineWords = readFile('Dokumen 1_Asli.txt')\n",
    "misspelledWords=[]\n",
    "correctSpelledWords=[]\n",
    "misspelledPrevious=dict()\n",
    "misspelledNext=dict()\n",
    "print('Word Index\\tWrong word\\tCorrect word\\tPrevious word\\tNext word')\n",
    "misspell_count=0\n",
    "no_of_words = -1\n",
    "if (len(correctLineWords) == len(errLineWords)):\n",
    "    no_of_words = len(errLineWords) #or len(correctLineWords) # as no of words are equal\n",
    "else:\n",
    "    print ('Error line and correct line have word count difference..Abort!!')\n",
    "for word_idx in range(no_of_words):\n",
    "    #Fungsi untuk membandingkan kata pada data uji dengan data asli dan pada kamus\n",
    "    if errLineWords[word_idx] != correctLineWords[word_idx] and errLineWords[word_idx] not in wordsList and errLineWords[word_idx] != '' and correctLineWords[word_idx] != '':\n",
    "        #print(errLineWords[word_idx], '====', correctLineWords[word_idx])\n",
    "        misspelledWords.append(errLineWords[word_idx])\n",
    "        correctSpelledWords.append(correctLineWords[word_idx])\n",
    "        #menentukan kata sebelum data uji (Wi-1)\n",
    "        misspelledPrevious[errLineWords[word_idx]] = errLineWords[word_idx-1]\n",
    "        #menentukan kata setelah data uji (Wi+1)\n",
    "        misspelledNext[errLineWords[word_idx]] = errLineWords[word_idx+ 1]\n",
    "        print(misspell_count, '\\t\\t',errLineWords[word_idx], '\\t\\t', correctLineWords[word_idx], '\\t\\t', misspelledPrevious[errLineWords[word_idx]], '\\t\\t', misspelledNext[errLineWords[word_idx]])\n",
    "        misspell_count+=1\n",
    "\n",
    "#Jumlah kata error/misspelled word yang dideteksi\n",
    "print('\\nTotal misspelled word count', misspell_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menemukan kandidat untuk semua ejaan kata salah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menemukan Kandidat kata dengan menggunakan jenis DLD, insertion, deletion, substitution, dan transposition\n",
    "def makeCandidates(word):\n",
    "    candidates=list()\n",
    "    charset='abcdefghijklmnopqrstuvwxyz' # alphabet charset\n",
    "    for char in charset:\n",
    "        #insertion candidates\n",
    "        for i in range(len(word)+1):\n",
    "            candidates.append(word[0:i]+char+word[i:]) \n",
    "        #substitution candidates\n",
    "        for i in range(len(word)):\n",
    "            candidates.append(word[0:i]+char+word[i+1:])\n",
    "    #deletion candidates\n",
    "    for i in range(len(word)):\n",
    "        candidates.append(word[0:i]+word[i+1:])\n",
    "    #transpose candidates\n",
    "    if(len(word)>1):\n",
    "        for i in range(len(word)-1):\n",
    "            candidates.append(word[0:i]+word[i+1]+word[i]+word[i+2:])\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Semua kandidat untuk misspelled word\n",
    "def getAllCandidates():\n",
    "    candidatesFirstEdit=list()\n",
    "    candidatesSecondEdit=list()\n",
    "    for errWord in misspelledWords:\n",
    "        candidatesFirstEdit+=makeCandidates(errWord)\n",
    "    for firstEditCandidate in candidatesFirstEdit:\n",
    "        candidatesSecondEdit+=makeCandidates(firstEditCandidate)\n",
    "    candidates=set(candidatesFirstEdit).union(set(candidatesSecondEdit)) # menghapus kata duplikat\n",
    "    candidates=set(wordsList).intersection(candidates) # menghapus kata invalid berdasarkan kata dikamus\n",
    "    return candidates\n",
    "candidates=getAllCandidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung nilai minimum dengan DLD misspelled word dari kandidat kata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMinimumEditDistance(str1, str2):\n",
    "    #str1: ejaan kata salah, str2: candidateWord\n",
    "    #insertion, deletion, substitution costs are 1\n",
    "    ic, dc, sc = 1, 1, 1\n",
    "    n, m=len(str1), len(str2)\n",
    "    MED_DP=[[0 for x in range(m + 1)] for x in range(n + 1)]  \n",
    "    for i in range(1,n+1):\n",
    "        MED_DP[i][0]=MED_DP[i-1][0]+dc\n",
    "    for i in range(1,m+1):\n",
    "        MED_DP[0][i]=MED_DP[0][i-1]+dc  \n",
    "    for i in range(1,n+1):\n",
    "        for j in range(1,m+1):\n",
    "            if (i>1 and j>1 and (str1[i-1]==str2[j-2]) and (str1[i-2]==str2[j-1])):\n",
    "                MED_DP[i][j]=MED_DP[i-2][j-2]+sc\n",
    "            elif(str1[i-1]==str2[j-1]):\n",
    "                MED_DP[i][j]=min([MED_DP[i-1][j]+dc,MED_DP[i-1][j-1]+0,MED_DP[i][j-1]+ic])\n",
    "            else:\n",
    "                MED_DP[i][j]=min([MED_DP[i-1][j]+dc,MED_DP[i-1][j-1]+sc,MED_DP[i][j-1]+ic])\n",
    "    #print(MED_DP)\n",
    "    return MED_DP[n][m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mendapatkan kandidat kata dengan memberikan edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateWords(err_word, med):\n",
    "    candidateWords=list()\n",
    "    for word in candidates:\n",
    "        MED=calculateMinimumEditDistance(err_word, word)\n",
    "        if MED <= med:\n",
    "            candidateWords.append(word)\n",
    "    return candidateWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mendapatkan tokens korpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingSetTokens():\n",
    "    with open('./Monolingual_corpus_Indonesian.txt', 'r', encoding='utf8', errors='ignore') as f:\n",
    "        tokens=[]\n",
    "        for line in f.readlines(): # training set\n",
    "            line=removePunct(line)\n",
    "            tokens+=line.split()\n",
    "        print(len(tokens))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi pembuatan NGram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNGram(n, tokens):\n",
    "    tokenlen=len(tokens)\n",
    "    nGramList=[]\n",
    "    for idx, token in enumerate(tokens):\n",
    "        singleNGramList=[]\n",
    "        for i in range(n):\n",
    "            if(idx+n<=tokenlen):\n",
    "                singleNGramList.append(tokens[idx+i])\n",
    "                #print(single_ngramlist)\n",
    "        if(len(singleNGramList)==n):\n",
    "            nGramList.append(tuple(singleNGramList))\n",
    "            #print(single_ngramlist)\n",
    "            #print(nGramList)\n",
    "    return nGramList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghitung kemunculan unigrams, bigrams dan trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1462186\n"
     ]
    }
   ],
   "source": [
    "def calculateCounts():\n",
    "    tokens=getTrainingSetTokens()\n",
    "    # fungsi membuat n-gram\n",
    "    unigramList=makeNGram(1, tokens)\n",
    "    bigramList=makeNGram(2, tokens)\n",
    "    trigramList=makeNGram(3, tokens)\n",
    "    #fungsi menghitung jumlah kemunculan n-gram\n",
    "    unigramCount=Counter(unigramList) #aggregate all unigrams\n",
    "    bigramCount=Counter(bigramList) #aggregate all bigrams\n",
    "    trigramCount=Counter(trigramList)\n",
    "    return unigramCount, bigramCount, trigramCount\n",
    "unigramCount, bigramCount, trigramCount = calculateCounts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung probabilitas dan skor kandidat kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(err_word, med):\n",
    "    #uniLambda = 0.15\n",
    "    biLambda = 0.4\n",
    "    triLambda = 0.6\n",
    "    V = len(unigramCount)\n",
    "    print(V)\n",
    "    N = sum(unigramCount.values())\n",
    "    candidateWordProbabilityDict=dict()\n",
    "    candidateWords = getCandidateWords(err_word, med)\n",
    "    #V = len(candidateWords)\n",
    "    prev_word = misspelledPrevious[err_word]\n",
    "    next_word = misspelledNext[err_word]\n",
    "    for word in candidateWords:       \n",
    "        #unigramProbability=(unigramCount[(word,)]+0.01)/(len(unigramCount)+(0.01*N))\n",
    "        #if bigramCount[(prev_word, word)]!=0:\n",
    "        #\n",
    "        bigramProbability=(bigramCount[(prev_word,word)]+0.01)/(unigramCount[(prev_word),]+(0.01*V))\n",
    "        #else:\n",
    "        #    bigramProbability=0\n",
    "        #if trigramCount[(prev_word, word, next_word)] != 0:\n",
    "        trigramProbability=(trigramCount[(prev_word,word,next_word)]+0.01)/(bigramCount[(prev_word),word]+(0.01*V))\n",
    "        #else:\n",
    "        #    trigramProbability=0\n",
    "        candidateWordProbability=bigramProbability*biLambda+trigramProbability*triLambda\n",
    "        #print(\"kata: \", word, \"\\t\\t\", candidateWordProbability)\n",
    "        if candidateWordProbability != 0:\n",
    "            candidateWordProbabilityDict[word] = candidateWordProbability\n",
    "    return candidateWordProbabilityDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menemukan probabilitas berdasarkan edit distance yang diberikan dan peringkat terhadap candidat yang mendekati kemungkinan menjadi koreksi kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordProbabilities(err_word, correct_word, med, top=10):\n",
    "    predictedWordsProbabilityDict = calculateProbability(err_word, med)\n",
    "    data =  sorted(predictedWordsProbabilityDict.items(), key=optr.itemgetter(1), reverse=True)[0:top]\n",
    "    foundIndex = -1\n",
    "    for idx, candidate_word in enumerate(data):\n",
    "        if correct_word in candidate_word[0]:\n",
    "            foundIndex = idx\n",
    "            break\n",
    "    return data, foundIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word index: 0 \t\t False word: penelitina \t True word: penelitian \t Previous word: berdasarkan \n",
      "\n",
      "37310\n",
      "True word found in top 10 predicted 1 edit distance candidates with bigram probability: :0.005492 \n",
      "\n",
      "Candidate Index\t\tCandidate word\t\t\tProbability\n",
      "\u001b[0;30;43m\u001b[1m0\t\t\tpenelitian\t\t\t0.0054924691787497665 ----> TRUE WORD\u001b[0m\n",
      "1\t\t\tpenelitinya\t\t\t2.180312160739958e-05\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Word index: 1 \t\t False word: ksalahan \t True word: kesalahan \t Previous word: bahwa \n",
      "\n",
      "37310\n",
      "True word found in top 10 predicted 1 edit distance candidates with bigram probability: :0.000191 \n",
      "\n",
      "Candidate Index\t\tCandidate word\t\t\tProbability\n",
      "\u001b[0;30;43m\u001b[1m0\t\t\tkesalahan\t\t\t0.0001910779293936624 ----> TRUE WORD\u001b[0m\n",
      "1\t\t\tkalahan\t\t\t1.6663289215245e-05\n",
      "2\t\t\tkealahan\t\t\t1.6663289215245e-05\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Word index: 2 \t\t False word: penggunan \t True word: penggunaan \t Previous word: kesalahan \n",
      "\n",
      "37310\n",
      "37310\n",
      "True word found in top 10 predicted 2 edit distance candidates with bigram probability: :0.000023 \n",
      "\n",
      "Candidate Index\t\tCandidate word\t\t\tProbability\n",
      "0\t\t\tpenghunian\t\t\t2.275816118531411e-05\n",
      "1\t\t\tpengagungan\t\t\t2.275816118531411e-05\n",
      "2\t\t\tpengimunan\t\t\t2.275816118531411e-05\n",
      "3\t\t\tpeneguhan\t\t\t2.275816118531411e-05\n",
      "\u001b[0;30;43m\u001b[1m4\t\t\tpenggunaan\t\t\t2.275816118531411e-05 ----> TRUE WORD\u001b[0m\n",
      "5\t\t\tpenganan\t\t\t2.275816118531411e-05\n",
      "6\t\t\tpenurunan\t\t\t2.275816118531411e-05\n",
      "7\t\t\tpengausan\t\t\t2.275816118531411e-05\n",
      "8\t\t\tpenenunan\t\t\t2.275816118531411e-05\n",
      "9\t\t\tpenghujan\t\t\t2.275816118531411e-05\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Word index: 3 \t\t False word: yng \t True word: yang \t Previous word: baca \n",
      "\n",
      "37310\n",
      "True word found in top 10 predicted 1 edit distance candidates with bigram probability: :0.000942 \n",
      "\n",
      "Candidate Index\t\tCandidate word\t\t\tProbability\n",
      "\u001b[0;30;43m\u001b[1m0\t\t\tyang\t\t\t0.0009424315215034773 ----> TRUE WORD\u001b[0m\n",
      "1\t\t\tung\t\t\t2.525368770523999e-05\n",
      "2\t\t\tng\t\t\t2.525368770523999e-05\n",
      "3\t\t\tyong\t\t\t2.525368770523999e-05\n",
      "4\t\t\tsng\t\t\t2.525368770523999e-05\n",
      "5\t\t\tong\t\t\t2.525368770523999e-05\n",
      "6\t\t\ting\t\t\t2.525368770523999e-05\n",
      "7\t\t\tang\t\t\t2.525368770523999e-05\n",
      "8\t\t\tyg\t\t\t2.525368770523999e-05\n",
      "9\t\t\tdng\t\t\t2.525368770523999e-05\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Word index: 4 \t\t False word: krangnya \t True word: kurangnya \t Previous word: karena \n",
      "\n",
      "37310\n",
      "True word found in top 10 predicted 1 edit distance candidates with bigram probability: :0.000387 \n",
      "\n",
      "Candidate Index\t\tCandidate word\t\t\tProbability\n",
      "\u001b[0;30;43m\u001b[1m0\t\t\tkurangnya\t\t\t0.0003874971553981718 ----> TRUE WORD\u001b[0m\n",
      "1\t\t\tkarangnya\t\t\t7.849887487425642e-05\n",
      "2\t\t\torangnya\t\t\t1.6699899124752655e-05\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Following are the word indices of words whose correct word was found in top 10 candidates:\n",
      " [0, 1, 2, 3, 4] \n",
      "\n",
      "Total misspelled words whose correct word was found 5 \n",
      "\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "found_idx=list()\n",
    "\n",
    "for idx, word in enumerate(misspelledWords):\n",
    "    print('Word index:', idx, '\\t\\t', 'False word:', word, '\\t', 'True word:', correctSpelledWords[idx], '\\t', 'Previous word:', misspelledPrevious[word], '\\n')\n",
    "    med = 1\n",
    "    predictedWordProbabilityDict, foundIndex = getWordProbabilities(word, correctSpelledWords[idx], med)\n",
    "    if foundIndex == -1:\n",
    "        med += 1\n",
    "        predictedWordProbabilityDict, foundIndex = getWordProbabilities(word, correctSpelledWords[idx], med)\n",
    "    if foundIndex == -1:\n",
    "        print ('True word not found in top 10', med, 'edit distance candidate words\\n')\n",
    "    else:\n",
    "        found_idx.append(idx)\n",
    "        print ('True word found in top 10 predicted', med, 'edit distance candidates with bigram probability: :%.6f' % predictedWordProbabilityDict[foundIndex][1], '\\n')\n",
    "    print ('Candidate Index\\t\\tCandidate word\\t\\t\\tProbability')\n",
    "    for idx1, candidate_word in enumerate(predictedWordProbabilityDict):\n",
    "        print_str = str(str(idx1) + '\\t\\t\\t' + candidate_word[0]) + '\\t\\t\\t' + str(candidate_word[1])\n",
    "        if foundIndex==idx1:\n",
    "            print_str =  '\\x1b[0;30;43m'+'\\33[1m'+print_str+' ----> TRUE WORD'+'\\x1b[0m'\n",
    "        print (str(print_str))\n",
    "    print ('----------------------------------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "print('Following are the word indices of words whose correct word was found in top 10 candidates:\\n', found_idx, '\\n')\n",
    "print('Total misspelled words whose correct word was found', len(found_idx), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
